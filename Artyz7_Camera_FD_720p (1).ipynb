{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Motion Detection (720p) on Arty Z7\n",
                "This notebook implements a real-time Motion Detection pipeline using Frame Differencing on the PYNQ framework."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pynq.overlays.base import BaseOverlay\n",
                "from pynq.lib.video import VideoMode\n",
                "import cv2\n",
                "import numpy as np\n",
                "import threading\n",
                "import queue\n",
                "import time\n",
                "import gc\n",
                "\n",
                "# Pipeline Configuration\n",
                "WIDTH, HEIGHT = 1280, 720\n",
                "PROCESS_SCALE = 0.3  # Process at 384x216 for stability\n",
                "BUFFER_SIZE = 2\n",
                "TARGET_FPS = 30\n",
                "MOTION_THRESHOLD = 25  # Lower = more sensitive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize FPGA Overlay and HDMI Output\n",
                "print(\"Initializing FPGA...\")\n",
                "base = BaseOverlay(\"base.bit\")\n",
                "hdmi_out = base.video.hdmi_out\n",
                "\n",
                "mode = VideoMode(WIDTH, HEIGHT, 24)\n",
                "hdmi_out.configure(mode)\n",
                "hdmi_out.start()\n",
                "print(f\"HDMI ready: {WIDTH}x{HEIGHT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize USB Camera\n",
                "print(\"Initializing camera...\")\n",
                "cap = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
                "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
                "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
                "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
                "cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)\n",
                "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
                "\n",
                "print(f\"Camera ready: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Shared State and Queues\n",
                "frame_queue = queue.Queue(maxsize=BUFFER_SIZE)\n",
                "result_queue = queue.Queue(maxsize=BUFFER_SIZE)\n",
                "\n",
                "class StreamState:\n",
                "    def __init__(self):\n",
                "        self.running = True\n",
                "        self.fps_capture = 0.0\n",
                "        self.fps_process = 0.0\n",
                "        self.fps_display = 0.0\n",
                "        self.motion_detected = False\n",
                "        self.motion_count = 0\n",
                "        self.dropped_frames = 0\n",
                "        \n",
                "state = StreamState()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Thread 1: Frame Capture\n",
                "def capture_thread():\n",
                "    frame_count = 0\n",
                "    last_reset = time.perf_counter()\n",
                "    \n",
                "    while state.running:\n",
                "        ret, frame = cap.read()\n",
                "        if not ret:\n",
                "            time.sleep(0.001)\n",
                "            continue\n",
                "        \n",
                "        if frame.shape[:2] != (HEIGHT, WIDTH):\n",
                "            frame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
                "        \n",
                "        try:\n",
                "            frame_queue.put(frame, block=False)\n",
                "            frame_count += 1\n",
                "        except queue.Full:\n",
                "            state.dropped_frames += 1\n",
                "        \n",
                "        # Calculate FPS every 30 frames with rolling window\n",
                "        if frame_count % 30 == 0:\n",
                "            now = time.perf_counter()\n",
                "            elapsed = now - last_reset\n",
                "            state.fps_capture = 30 / elapsed\n",
                "            last_reset = now"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Thread 2: Motion Detection (Frame Differencing)\n",
                "def detection_thread():\n",
                "    \"\"\"Lightweight motion detection using frame differencing\"\"\"\n",
                "    prev_gray = None\n",
                "    process_w = int(WIDTH * PROCESS_SCALE)\n",
                "    process_h = int(HEIGHT * PROCESS_SCALE)\n",
                "    \n",
                "    frame_count = 0\n",
                "    last_reset = time.perf_counter()\n",
                "    \n",
                "    # Morphology kernel for noise reduction\n",
                "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
                "    \n",
                "    while state.running:\n",
                "        try:\n",
                "            frame = frame_queue.get(timeout=0.1)\n",
                "        except queue.Empty:\n",
                "            continue\n",
                "        \n",
                "        # Downscale for processing\n",
                "        small = cv2.resize(frame, (process_w, process_h))\n",
                "        gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
                "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
                "        \n",
                "        motion_contours = []\n",
                "        \n",
                "        if prev_gray is not None:\n",
                "            # Frame difference\n",
                "            diff = cv2.absdiff(prev_gray, gray)\n",
                "            _, thresh = cv2.threshold(diff, MOTION_THRESHOLD, 255, cv2.THRESH_BINARY)\n",
                "            \n",
                "            # Remove noise\n",
                "            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
                "            thresh = cv2.dilate(thresh, kernel, iterations=2)\n",
                "            \n",
                "            # Find contours\n",
                "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "            \n",
                "            # Filter small movements and scale back\n",
                "            scale_factor = 1.0 / PROCESS_SCALE\n",
                "            for c in contours:\n",
                "                if cv2.contourArea(c) > 100:  # Minimum area\n",
                "                    x, y, w, h = cv2.boundingRect(c)\n",
                "                    motion_contours.append((\n",
                "                        int(x * scale_factor),\n",
                "                        int(y * scale_factor),\n",
                "                        int(w * scale_factor),\n",
                "                        int(h * scale_factor)\n",
                "                    ))\n",
                "            \n",
                "            # Update state\n",
                "            state.motion_detected = len(motion_contours) > 0\n",
                "            state.motion_count = len(motion_contours)\n",
                "        \n",
                "        prev_gray = gray\n",
                "        \n",
                "        try:\n",
                "            result_queue.put((frame, motion_contours), block=False)\n",
                "            frame_count += 1\n",
                "        except queue.Full:\n",
                "            pass\n",
                "        \n",
                "        # Calculate FPS every 30 frames with rolling window\n",
                "        if frame_count % 30 == 0:\n",
                "            now = time.perf_counter()\n",
                "            elapsed = now - last_reset\n",
                "            state.fps_process = 30 / elapsed\n",
                "            last_reset = now"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Thread 3: HDMI Display Output\n",
                "def display_thread():\n",
                "    prev_time = time.perf_counter()\n",
                "    fps_smooth = 0.0\n",
                "    \n",
                "    hdmi_buffer = hdmi_out.newframe()\n",
                "    \n",
                "    while state.running:\n",
                "        try:\n",
                "            frame, contours = result_queue.get(timeout=0.1)\n",
                "        except queue.Empty:\n",
                "            continue\n",
                "        \n",
                "        # Measure actual time between frames\n",
                "        current_time = time.perf_counter()\n",
                "        time_diff = current_time - prev_time\n",
                "        prev_time = current_time\n",
                "        \n",
                "        # Draw motion boxes\n",
                "        for (x, y, w, h) in contours:\n",
                "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
                "        \n",
                "        # Status overlay\n",
                "        status_color = (0, 255, 0) if state.motion_detected else (100, 100, 100)\n",
                "        status_text = \"MOTION\" if state.motion_detected else \"NO MOTION\"\n",
                "        cv2.putText(frame, status_text, (20, 50), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, status_color, 2)\n",
                "        \n",
                "        # Performance stats\n",
                "        cv2.putText(frame, f\"Capture: {state.fps_capture:.1f} FPS\", (20, 95), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
                "        cv2.putText(frame, f\"Process: {state.fps_process:.1f} FPS\", (20, 130), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
                "        cv2.putText(frame, f\"Display: {fps_smooth:.1f} FPS\", (20, 165), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
                "        \n",
                "        cv2.putText(frame, f\"Motion Regions: {state.motion_count}\", (20, 200), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
                "        \n",
                "        if state.dropped_frames > 0:\n",
                "            cv2.putText(frame, f\"Dropped: {state.dropped_frames}\", (20, 235), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
                "        \n",
                "        # Resolution indicator\n",
                "        cv2.putText(frame, \"1280x720\", (WIDTH - 180, 50), \n",
                "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)\n",
                "        \n",
                "        # Convert and write to HDMI\n",
                "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "        hdmi_buffer[:] = frame_rgb\n",
                "        hdmi_out.writeframe(hdmi_buffer)\n",
                "        \n",
                "        # Calculate actual FPS\n",
                "        if time_diff > 0:\n",
                "            instant_fps = 1.0 / time_diff\n",
                "            fps_smooth = 0.9 * fps_smooth + 0.1 * instant_fps\n",
                "        \n",
                "        state.fps_display = fps_smooth"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main Execution Loop\n",
                "print(\"LIGHTWEIGHT MOTION DETECTION PIPELINE (720p)\")\n",
                "\n",
                "try:\n",
                "    threads = [\n",
                "        threading.Thread(target=capture_thread, daemon=True),\n",
                "        threading.Thread(target=detection_thread, daemon=True),\n",
                "        threading.Thread(target=display_thread, daemon=True)\n",
                "    ]\n",
                "    \n",
                "    for t in threads:\n",
                "        t.start()\n",
                "    \n",
                "    print(\"Pipeline started\")\n",
                "    \n",
                "    # Monitor pipeline\n",
                "    while True:\n",
                "        time.sleep(5)\n",
                "        print(f\"[Status] FPS: Cap={state.fps_capture:.1f} | Proc={state.fps_process:.1f} | Disp={state.fps_display:.1f} | Drops={state.dropped_frames}\")\n",
                "\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\nStopping...\")\n",
                "    state.running = False\n",
                "    \n",
                "    for t in threads:\n",
                "        t.join(timeout=1.0)\n",
                "    \n",
                "finally:\n",
                "    print(\"Cleanup...\")\n",
                "    cap.release()\n",
                "    hdmi_out.stop()\n",
                "    del hdmi_out\n",
                "    gc.collect()\n",
                "    print(\"Resources Released.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}